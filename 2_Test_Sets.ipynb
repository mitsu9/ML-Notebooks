{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、データの取り扱いについて述べていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Sets\n",
    "- https://developers.google.com/machine-learning/crash-course/training-and-test-sets/splitting-data\n",
    "- https://developers.google.com/machine-learning/crash-course/validation/another-partition\n",
    "\n",
    "データは大きく３種類に分けられる\n",
    "- Training Set（学習データ）\n",
    "- Validation Set（検証データ）\n",
    "- Test Set（テストデータ）\n",
    "\n",
    "まず、学習用データとテストデータは必ず分ける。\n",
    "なぜなら、テストデータが無ければ学習した結果を評価できないからである。\n",
    "ここで、学習するときに必ずテストデータを使わないように気をつける。\n",
    "テストデータを用いて学習してしまうと、学習結果はテストデータに適合してしまう。\n",
    "\n",
    "しかし、学習用データとテスト用データを分けるだけでは不十分である。\n",
    "なぜなら、学習用データで学習する→テスト用データでテストする→パラメータ等を変化して学習用データで学習する→テスト用データでテストする、のように改善していったとき、テスト用データに適合してしまうからである。\n",
    "そこで、改善の際に利用するデータと最終的にその学習結果を評価する時のデータを分ける必要がある。\n",
    "したがって、学習用データ、検証用データ、テストデータと3種類のデータに分けて学習をおこなう。\n",
    "\n",
    "<img src=\"assets/workflow.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation\n",
    "### Feature Engineering\n",
    "https://developers.google.com/machine-learning/crash-course/representation/feature-engineering\n",
    "\n",
    "Feature Engineeringとは、rawデータを学習できるデータ(feature vector)に変換すること。\n",
    "\n",
    "<img src=\"assets/feature_engineering.png\">\n",
    "\n",
    "元データが数字の時は簡単。文字の時が問題になる。\n",
    "\n",
    "→コンフルに書いたようないろいろな手法がある。\n",
    "\n",
    "\n",
    "### Qualities of Good Features\n",
    "https://developers.google.com/machine-learning/crash-course/representation/qualities-of-good-features\n",
    "\n",
    "ここでは良いfeatureについて説明する。\n",
    "\n",
    "良いfeatureの値とは、5回以上は出現するデータである。\n",
    "\n",
    "出てくる回数が少ないとその値に対しての学習がおこなえない。\n",
    "\n",
    "また、それぞれのfeatureの値はわかりやすく明確な意味がないといけない。\n",
    "例えば年齢を年で表示せず秒で表示するなどしてはいけない。\n",
    "なぜなら、その値がおかしいデータなのかどうかがすぐにわからなくなってしまうから。\n",
    "\n",
    "featureの定義が変わらないようにする。\n",
    "アイテムの種類を数字で表現するなどした場合に、その数字の意味が変わってしまうことがあるので注意。\n",
    "\n",
    "### Cleaning data\n",
    "https://developers.google.com/machine-learning/crash-course/representation/cleaning-data\n",
    "\n",
    "学習用データ、テスト用データに悪いデータが混ざっている場合、それらを掃除しなければ良い結果は得られない。\n",
    "ここでは、いくつかのデータをきれいにする方法を紹介する。\n",
    "\n",
    "- Scaling\n",
    "  - データの範囲が[100,900]とかの場合に[0,1]や[-1,+1]のように扱いやすい範囲に直すこと\n",
    "  - よくある方法は標準化すること\n",
    "  $$(value - mean) / stddev.$$\n",
    "  - 複数のデータを同じスケールに合わせる必要は無い\n",
    "  - scalingするメリットは以下の通り\n",
    "    - 最急降下法で極小値にたどり着くのが早くなる\n",
    "    - NaN trapを回避することができる。NaN trap = 数字が大きくなりすぎてfloatの限界を突破すること\n",
    "    - 学習する際に考えないといけないことを減らすことができる。scalingしないとさらに大きなデータがある可能性を考慮しなければならなくなる。\n",
    "- 外れ値の扱い方（とても長いロングテールがある場合）\n",
    "  - logを取るとレンジが狭くなる。（logを取る時は最小値>1になるように元の値に+1するなど工夫が必要）\n",
    "  - ある値以上のものは全てある値とする。例えば4.0以上のものは全て4.0に直す。6.0->4.0, 4.5->4.0とする。\n",
    "- Binning\n",
    "  - ある範囲に入っている値をまとめてカウントする\n",
    "  - 100点満点のテストで10点ごとに区切るなど。0<= x < 10のもの、10<= x < 20のもの、といった具合\n",
    "  - この場合いくつのグループに分けられるかを知っているのでベクトル化することができる\n",
    "  - 100点のテストを10点で区切る場合10個に分けられる→例えば5点の場合 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] と表現できる\n",
    "- Scrubbing\n",
    "  - 信頼できないデータを捨てること\n",
    "  - Omitted value : 打ち忘れなどで入力されていない項目があるデータ\n",
    "  - Duplicate examples : 同じログが2回記録されているなどで重複しているもの\n",
    "  - Bad labels : 人が入力した際に間違えてラベル付けされたもの。犬の写真に猫とラベル付けされていたりなど\n",
    "  - Bad feature values : 範囲外の値が入っていたりするなど値が明らかに間違いなもの\n",
    "\n",
    "これらの手法を用いて良いデータセットにすることでより良い学習をすることができる。\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
